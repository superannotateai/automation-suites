{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "debab20c-466d-4034-b170-4734f851051a",
   "metadata": {},
   "source": [
    "<img src=\"../docs/sa_logo.png\" width=\"250\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd5c92-b88a-4975-befa-ee2e84675e7b",
   "metadata": {
    "colab_type": "text",
    "id": "PGnlRWvkY-2c"
   },
   "source": [
    "# Named Entity Recognition with HuggingFace BERT and SuperAnnotate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0adbbe-3f0d-4c93-ace8-5a64b83811df",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d890e68-1417-4b8f-91f8-71d111b210ae",
   "metadata": {},
   "source": [
    "This tutorial shows an example of solving ```Named Entity Recognition task``` with [SuperAnnotate](https://www.superannotate.com/) and [HuggingFace](https://huggingface.co/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de6662-f702-4831-8731-30e2e923d673",
   "metadata": {},
   "source": [
    "The main goal of this tutorial is to show how one could annotate some part of data with ```SuperAnnotate``` tools and then build a model with ```HuggingFace``` to automatically annotate the rest of data and upload new annotations to [SuperAnnotate platform](https://app.superannotate.com/). These automatically generated annotations may be additionaly checked and modified manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31799dad-814b-470b-9eb2-0c46f190fcba",
   "metadata": {},
   "source": [
    "All the experiments described in this tutorial were done with [Legal NER](https://paperswithcode.com/dataset/legal-ner) dataset. It is a corpus of 46545 annotated legal named entities mapped to 14 legal entity types. It is designed for named entity recognition in indian court judgement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9332327",
   "metadata": {},
   "source": [
    "![](../docs/legal-ner/folders_legal_ner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51494c70-acf6-42c3-b7fb-26e400670a2b",
   "metadata": {},
   "source": [
    "The tutorial starts with the assumption that we have partially annotated dataset of texts.\n",
    "The data is stored on S3 bucket and splitted into two parts: \n",
    "* **train** (~40%) $-$ annotated data for training\n",
    "* **unlabeled** (~60%) $-$ data that will be annotated by the model\n",
    "\n",
    "These folders are connected with existing project on [SuperAnnotate platform](https://app.superannotate.com/) and train dataset has already been annotated manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9eca6",
   "metadata": {},
   "source": [
    "![](../docs/legal-ner/ner_text_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc6e1c5-ad12-43ca-a0f8-82abec50f3d7",
   "metadata": {},
   "source": [
    "In the examples below we used ```SuperAnnotate SDK```, ```Boto3 SDK``` and ```HuggingFace```. $\\ $\n",
    "Some parts of code used here are provided as examples in [SuperAnnotate](https://doc.superannotate.com/docs/getting-started), [Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) and  [HuggingFace](https://huggingface.co/) documentations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95907ec6-755e-47bb-a7b2-388a19f9e50c",
   "metadata": {},
   "source": [
    "In this tutorial we will go through the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0fbc97",
   "metadata": {},
   "source": [
    "$\\textbf{1.}$ [Environmental setup](#environmental_setup)\n",
    "\n",
    "$\\textbf{1.1}$ [User Variables Setup](#user_variables)\n",
    "\n",
    "$\\textbf{1.1}$ [Constants Setup](#constants_setup)\n",
    "\n",
    "$\\textbf{2.}$ [Download documents and labels from SuperAnnotate](#download_data)\n",
    "\n",
    "$\\textbf{2.1}$ [Get links to all files in S3 bucket](#list_all_files_s3)\n",
    "\n",
    "$\\textbf{2.2}$ [Download files](#download_files)\n",
    "\n",
    "$\\textbf{2.3}$ [Download labels from SuperAnnotate](#download_labels_from_sa)\n",
    "   \n",
    "$\\textbf{3.}$ [Prepare data for Bert NER model](#prepare_data_for_bert_model)\n",
    "\n",
    "$\\textbf{4.}$ [Train model](#train_model)\n",
    "\n",
    "$\\textbf{5.}$ [Evaluate model](#evaluate_model)\n",
    "\n",
    "$\\textbf{6.}$ [Get predictions for unlabeled texts](#get_predictions_for_unlabeled_texts)\n",
    "\n",
    "$\\textbf{7.}$ [Make annotations in SuperAnnotate format](#make_annotations_sa_format)\n",
    "\n",
    "$\\textbf{8.}$ [Upload new annotations to SuperAnnotate platform](#upload_new_annotations_to_sa_platform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c410908-a26b-426e-bc9d-f6e610f50819",
   "metadata": {},
   "source": [
    "## 1. Environmental setup\n",
    "<a id='environmental_setup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca537e-ba33-4389-a5ba-bbc97b062515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install superannotate==4.4.7 #SA SDK installation\n",
    "! pip install boto3 # install boto3 client\n",
    "! pip install transformers # HuggingFace transformers\n",
    "! pip install seqeval # model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6dae51-a536-4190-9c01-d03dc8382fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.scheme import IOB2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from superannotate import SAClient\n",
    "from transformers import BertTokenizerFast\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD, Adam, NAdam\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6568072d-a330-488d-9630-f34972afef28",
   "metadata": {},
   "source": [
    "### 1.1 User Variables Setup\n",
    "<a id='user_variables'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca3da4-3b45-41bf-af85-641319925f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SuperAnnotate SDK token\n",
    "SA_TOKEN = \"ADD_YOUR_TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b6c4e-f744-4202-9221-4fac99a09e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_PROJECT_NAME = \"ADD_SUPERANNOTATE_PROJECT_NAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e907de6f-8e3d-4713-88fe-8a224669b6c2",
   "metadata": {},
   "source": [
    "### 1.2 Constants Setup\n",
    "<a id='constants_setup'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e299497-b21e-4fc8-8839-9b36b2254126",
   "metadata": {
    "tags": []
   },
   "source": [
    "SuperAnnotate Python SDK functions work within the team scope of the platform, so a team-level authorization is required.\n",
    "\n",
    "To authorize the package in a given team scope, get the authorization token from the team settings page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f2a8a-640e-4421-92fa-98448985bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_client = SAClient(token=SA_TOKEN) ## SuperAnnotate client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486ae6e",
   "metadata": {},
   "source": [
    "## 2. Download documents and labels from SuperAnnotate\n",
    "<a id='download_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178726a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'sa-public-datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfa6805-b1e5-48ea-a4e0-e58963846380",
   "metadata": {},
   "source": [
    "Data that is shown on SuperAnnotate page is actually stored on AWS S3 Bucket.\n",
    "Here we provide name of this bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c0bff-ba69-47ac-8b2f-79b711cd84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"ADD_YOUR_BUCKET_NAME\" # bucket where the data is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfbb793-7728-4722-acce-ef35f4b55ca2",
   "metadata": {},
   "source": [
    "We should also create client to be able to work with AWS S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83107e9-8496-4512-b98e-5d99871c7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3') ## S3 client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e23db5",
   "metadata": {},
   "source": [
    "### 2.1. Get links to all files in S3 bucket\n",
    "<a id='list_all_files_s3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b37f9f-3474-4f8c-97b4-6668ae1ca816",
   "metadata": {},
   "source": [
    "Texts shown on SuperAnnotate page are stored in S3 bucket.\n",
    "We can download them to local computer and train our model for legal entities recognition.\n",
    "\n",
    "Before that we should get links to all of them.\n",
    "Since S3 SDK could list only 1000 objects per step, we could do it iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80382016",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_names = ['train', 'unlabeled']\n",
    "\n",
    "data_links_dict = {'train': [],\n",
    "                   'unlabeled': []}\n",
    "\n",
    "BUCKET_FOLDER_PATH = '/path/to/data/'\n",
    "\n",
    "start_key = ''\n",
    "\n",
    "for subset_name in subset_names:\n",
    "    print(\"Processing\", subset_name)\n",
    "    while True:\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name,\n",
    "                                             Prefix=f'{BUCKET_FOLDER_PATH}/{subset_name}/',\n",
    "                                             StartAfter=start_key)\n",
    "        objects = response['Contents']\n",
    "        for obj in objects:\n",
    "            data_links_dict[subset_name].append(obj['Key'])\n",
    "        print(f\"\\t{len(data_links_dict[subset_name])} files in {subset_name}\")\n",
    "        start_key = objects[-1]['Key']\n",
    "        if len(objects) < 1000:\n",
    "            start_key = ''\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c191650a",
   "metadata": {},
   "source": [
    "### 2.2. Download files\n",
    "<a id='download_files'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892942fe-9b07-4e01-b0d1-b8c4b60920fb",
   "metadata": {},
   "source": [
    "Now we will use these links to download all the files from S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216dfcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset_name in subset_names:\n",
    "    print(f\"Loading {subset_name} docs\")\n",
    "    save_dir = f'./{subset_name}_sa_docs'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    for file_key in tqdm(data_links_dict[subset_name]):\n",
    "        if not '.txt' in file_key:\n",
    "            continue\n",
    "        filename = os.path.basename(file_key)\n",
    "        s3_client.download_file(Bucket=bucket_name, \n",
    "                                Key=file_key,\n",
    "                                Filename=os.path.join(save_dir, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36049c",
   "metadata": {},
   "source": [
    "### 2.3 Download labels from SuperAnnotate\n",
    "<a id='download_labels_from_sa'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c569da6-7eb9-4a62-afef-8764aa2fce1a",
   "metadata": {},
   "source": [
    "Now we can download labels from SuperAnnotate for the train texts that were annotated manually. The annotations will be downloaded in [SuperAnnotate format](https://doc.superannotate.com/docs/sdk-export-annotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff0e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"PUT_YOUR_TOKEN_HERE\"\n",
    "\n",
    "sa_client = SAClient(token = token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_response = sa_client.get_annotations(project=\"Legal-NER/train\",\n",
    "                                        items=[os.path.basename(x) for x \\\n",
    "                                               in data_links_dict['train']])\n",
    "\n",
    "annotations = [i['instances'] for i in sa_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set([entity['className'] for a in annotations for entity in a])\n",
    "unique_labels.add('O')\n",
    "\n",
    "print(\"All unique labels found in training data: \")\n",
    "for label in unique_labels:\n",
    "    print(f\"\\t{label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c763fb0d-44bb-48df-ba7c-b0648c8b3ea0",
   "metadata": {},
   "source": [
    "We will map each label into its id and id into label for the BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d74089",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {k: v for v, k in enumerate(sorted(unique_labels))}\n",
    "id2label = {v: k for v, k in enumerate(sorted(unique_labels))}\n",
    "\n",
    "for i,l in id2label.items():\n",
    "    print(f\"{i} : {l}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8149d73e",
   "metadata": {},
   "source": [
    "## 3. Prepare data for Bert NER model\n",
    "<a id='prepare_data_for_bert_model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7125cf-7d46-4ff6-b111-35112c645146",
   "metadata": {},
   "source": [
    "We will use pretrained tokenizer bert-base-cased for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deebb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "\n",
    "PAD_TOKEN_ID = -100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d6c6d-fa38-4686-a3a0-476d71d93c92",
   "metadata": {},
   "source": [
    "We should align named entities that we downloaded in [SuperAnnotate format](https://doc.superannotate.com/docs/sdk-export-annotations) with tokens we get from tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dad3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_label(txt_tokenized, entities, label2id):\n",
    "    label_ids = []\n",
    "    cnt = 0\n",
    "    for word_idx, (start,end) in zip(txt_tokenized.word_ids(), txt_tokenized['offset_mapping'][0]):\n",
    "        if word_idx is None:\n",
    "            label_ids.append(PAD_TOKEN_ID)\n",
    "            continue\n",
    "        found_entity = False\n",
    "        for entity in entities:\n",
    "            if entity['start'] <= int(start) and entity['end'] >= int(end) and not found_entity:\n",
    "                label = entity['className']\n",
    "                label_ids.append(label2id[label])\n",
    "                found_entity = True\n",
    "                break\n",
    "        if not found_entity:\n",
    "            label_ids.append(label2id['O'])\n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142f392e-e19a-45c5-a458-d3f9003b78ee",
   "metadata": {},
   "source": [
    "And now we can create class for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789fc352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSequence(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, entities=None, label2id=None):\n",
    "        if not entities:\n",
    "            entities = [[] for t in texts]\n",
    "        configured_tokenizer = lambda text: tokenizer(str(i),\n",
    "                                                      padding='max_length',\n",
    "                                                      max_length=512,\n",
    "                                                      truncation=True,\n",
    "                                                      return_tensors=\"pt\",\n",
    "                                                      return_offsets_mapping=True,\n",
    "                                                      return_length=True)\n",
    "        self.texts = [configured_tokenizer(text) for text in texts]\n",
    "        self.labels = [align_label(i, j, label2id) for i,j in zip(self.texts, entities)]\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_data(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        return torch.LongTensor(self.labels[idx])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_data = self.get_batch_data(idx)\n",
    "        batch_labels = self.get_batch_labels(idx)\n",
    "        return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d92943b-a79e-45fa-89fa-fdc20ce40ca9",
   "metadata": {},
   "source": [
    "Now we upload train texts that we downloaded from S3 bucket and split them into train, validation and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c19794",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DOCS_FOLDER = f'./train_sa_docs'\n",
    "\n",
    "texts = []\n",
    "\n",
    "for filename in glob.glob(TRAIN_DOCS_FOLDER):\n",
    "    with open(filename) as f:\n",
    "        line = f.read()\n",
    "        texts.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c943506",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, valid_texts, train_entities, valid_entities = train_test_split(texts, annotations, test_size=0.2)\n",
    "val_texts, test_texts, val_entities, test_entities = train_test_split(valid_texts, valid_entities, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d06e8",
   "metadata": {},
   "source": [
    "## 4. Train model\n",
    "<a id='train_model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ee5aa-24e3-47ac-b2fd-80238b43d5a6",
   "metadata": {},
   "source": [
    "Let's now declare class for our token classification model and implement the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BertModel, self).__init__()\n",
    "        self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_labels))\n",
    "\n",
    "    def forward(self, input_id, mask, label):\n",
    "        output = self.bert(input_ids=input_id,\n",
    "                           attention_mask=mask,\n",
    "                           labels=label,\n",
    "                           return_dict=False)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5e3ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(model, train_texts, train_entities, val_texts, val_entities, label2id):\n",
    "\n",
    "    train_dataset = DataSequence(train_texts, train_entities, label2id)\n",
    "    val_dataset = DataSequence(val_texts, val_entities, label2id)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   num_workers=4,\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   shuffle=True)\n",
    "    \n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                                 num_workers=4,\n",
    "                                                 batch_size=BATCH_SIZE)\n",
    "    \n",
    "    train_size = len(train_texts)\n",
    "    val_size = len(val_texts)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    optimizer = NAdam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    best_acc = 0\n",
    "    best_loss = 1000\n",
    "\n",
    "    for epoch_num in range(EPOCHS):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for train_data, train_label in tqdm(train_dataloader):\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_data['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = train_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss, logits = model(input_id, mask, train_label)\n",
    "\n",
    "            for i in range(logits.shape[0]):\n",
    "\n",
    "                logits_clean = logits[i][train_label[i] != PAD_TOKEN_ID]\n",
    "                label_clean = train_label[i][train_label[i] != PAD_TOKEN_ID]\n",
    "\n",
    "                predictions = logits_clean.argmax(dim=1)\n",
    "                acc = (predictions == label_clean).float().mean()\n",
    "                total_acc_train += acc\n",
    "                total_loss_train += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        for val_data, val_label in val_dataloader:\n",
    "\n",
    "            val_label = val_label.to(device)\n",
    "            mask = val_data['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = val_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            loss, logits = model(input_id, mask, val_label)\n",
    "\n",
    "            for i in range(logits.shape[0]):\n",
    "                logits_clean = logits[i][val_label[i] != PAD_TOKEN_ID]\n",
    "                label_clean = val_label[i][val_label[i] != PAD_TOKEN_ID]\n",
    "\n",
    "                predictions = logits_clean.argmax(dim=1)\n",
    "                acc = (predictions == label_clean).float().mean()\n",
    "                total_acc_val += acc\n",
    "                total_loss_val += loss.item()\n",
    "\n",
    "        val_accuracy = total_acc_val / len(val_texts)\n",
    "        val_loss = total_loss_val / len(val_texts)\n",
    "\n",
    "        print(\n",
    "            f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / train_size: .3f} | Accuracy: {total_acc_train / train_size: .3f} | Val_Loss: {total_loss_val / val_size: .3f} | Accuracy: {total_acc_val / val_size: .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 5e-3\n",
    "EPOCHS = 7\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6081580",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env TOKENIZERS_PARALLELISM=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18cb8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BertModel()\n",
    "train_loop(model, train_texts, train_entities, val_texts, val_entities, label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6add9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Evaluate model\n",
    "<a id='evaluate_model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce837b1-6c41-4416-b580-045579b6b152",
   "metadata": {
    "tags": []
   },
   "source": [
    "After the training is done we could evaluate our model on test data. \n",
    "We could use [seqeval](https://huggingface.co/spaces/evaluate-metric/seqeval) to get span-based metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff59a1c7-10ea-48d3-a9e9-e49d58fc75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_texts, test_labels, label2id):\n",
    "    \n",
    "    return_data = []\n",
    "\n",
    "    test_dataset = DataSequence(test_texts, test_labels, label2id)\n",
    "    \n",
    "    test_dataloader = DataLoader(test_dataset, num_workers=4, batch_size=1)\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    model = model.to(device)\n",
    "\n",
    "    for test_data, test_label in test_dataloader:\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_data['attention_mask'].squeeze(1).to(device)\n",
    "\n",
    "            input_id = test_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            loss, logits = model(input_id, mask, test_label)\n",
    "\n",
    "            for i in range(logits.shape[0]):\n",
    "                logits_clean = logits[i][test_label[i] != PAD_TOKEN_ID]\n",
    "                label_clean = test_label[i][test_label[i] != PAD_TOKEN_ID]\n",
    "                predictions = logits_clean.argmax(dim=1)\n",
    "                return_data.append((test_data, predictions, label_clean))\n",
    "    \n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d1755-af30-40e4-81a5-2c24be94460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data = evaluate(model, test_texts, test_entities, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b076867",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [x[0] for x in evaluation_data]\n",
    "predictions = [x[1] for x in evaluation_data]\n",
    "label_clean = [x[2] for x in evaluation_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd08dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_iob = [[id2label[int(i)] for i in sent_lb] for sent_lb in predictions]\n",
    "label_clean_iob = [[id2label[int(i)] for i in sent_lb] for sent_lb in label_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ec82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predictions_iob, label_clean_iob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87781cb",
   "metadata": {},
   "source": [
    "## 6. Get predictions for unlabeled texts\n",
    "<a id='get_predictions_for_unlabeled_texts'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416756a9-72e1-49a6-b1a6-2e75bbb874cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_texts = []\n",
    "names = []\n",
    "for filename in glob.glob('./unlabeled_sa_docs/*.txt'):\n",
    "    with open(filename) as f:\n",
    "        unlabeled_texts.append(f.read())\n",
    "        names.append(os.path.basename(filename)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c87c1b-736a-4b19-a3c6-a221337bad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_unlabeled = evaluate(model=model,\n",
    "                            test_texts=unlabeled_texts[:100],\n",
    "                            test_labels=[],\n",
    "                            label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c6ed6-d983-4daa-a19e-77e27a0a612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [x[0] for x in output_unlabeled]\n",
    "predictions = [x[1] for x in output_unlabeled]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f87c4c",
   "metadata": {},
   "source": [
    "## 7. Make annotations in SuperAnnotate format\n",
    "<a id='make_annotations_sa_format'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ab3dc-e27f-4aa9-b23b-7649e26ed782",
   "metadata": {},
   "source": [
    "Based on predictions made by the model we should now create annotations in SuperAnnotate format to be able to upload them to SuperAnnotate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f24e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_pred_to_annotations(tokenized_texts, predictions, ids_to_labels, names):\n",
    "    annotations = []\n",
    "    for text, labels, name in zip(tokenized_texts, predictions, names):\n",
    "        entities = []\n",
    "        for i, label_id in enumerate(labels):\n",
    "            start, end = text['offset_mapping'][0][0][i+1]\n",
    "            label = ids_to_labels[label_id.item()]\n",
    "            if not label == 'O':\n",
    "                entities.append({\"type\": \"entity\",\n",
    "                                 \"className\": label,\n",
    "                                 \"start\": start.item(),\n",
    "                                 \"end\": end.item() + 1,\n",
    "                                 \"attributes\": []\n",
    "                                 })\n",
    "        annotations.append({'instances': entities,\n",
    "                            'metadata': {'name' : name}})\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda297a-4443-4d25-8ad9-25beeb8ad478",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_annotations = bert_pred_to_annotations(tokenized_texts,predictions,id2label,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_FOLDER = 'PATH/TO/LOCAL/DIR/' # local folder to store .json files with annotations\n",
    "for annotation in new_annotations:\n",
    "    filename = annotation['metadata']['name']\n",
    "    with open(f'{ANNOTATIONS FOLDER}/{filename}.json','w') as f:\n",
    "        json.dump(js_annotation, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a14e9",
   "metadata": {},
   "source": [
    "## 8. Upload new annotations to SuperAnnotate platform\n",
    "<a id='upload_new_annotations_to_sa_platform'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c729b-da73-4139-b338-59843e17ff10",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we could upload annotations generated on the previous step back to SuperAnnnotate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccdb405-e4f0-4bd1-a89a-1a7cc9831947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_js(filename):\n",
    "    with open(filename) as f:\n",
    "        js = json.load(f)\n",
    "    return js "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd96a609-81be-4ec4-9ba5-9f9ac8f84393",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "files = os.listdir(ANNOTATIONS_FOLDER)\n",
    "files_per_step = 500\n",
    "steps = len(files) // files_per_step + 1\n",
    "\n",
    "for step in range(steps):\n",
    "    start = step * files_per_step\n",
    "    end = min((step + 1)* files_per_step, len(files))\n",
    "\n",
    "    batch = [read_js(os.path.join(ANNOTATIONS_FOLDER, f)) for f in files[start: end]]\n",
    "\n",
    "    outputs.append(sa_client.upload_annotations(project=f'{SA_PROJECT_NAME}/unlabeled/', annotations=batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5fa4cc-d03c-41e1-8195-e8f49c0b33b0",
   "metadata": {},
   "source": [
    "Now we can look at unlabeled folder at the SuperAnnotate page and see the predictions made by our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d6669d",
   "metadata": {},
   "source": [
    "![](../docs/legal-ner/labeled_unlabeled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be44fd-6633-4ad9-8563-070f21a9c276",
   "metadata": {},
   "source": [
    "All files in unlabeled folder changed their status."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1be97b",
   "metadata": {},
   "source": [
    "![](../docs/legal-ner/new_labels_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524706be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
