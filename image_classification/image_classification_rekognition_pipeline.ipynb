{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ea2b42",
   "metadata": {},
   "source": [
    "<img src=\"../docs/sa_logo.png\" width=\"250\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d490737",
   "metadata": {},
   "source": [
    "# Image Classification with Amazon Rekognition and SuperAnnotate \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b93262",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d83a8",
   "metadata": {},
   "source": [
    "This tutorial shows an example of solving ```Image classification task``` with [SuperAnnotate](https://www.superannotate.com/) and [Amazon Rekognition](https://us-west-2.console.aws.amazon.com/rekognition/home?region=us-west-2#/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4c4f0",
   "metadata": {},
   "source": [
    "The main goal of this tutorial is to show how one could annotate some part of data with ```SuperAnnotate``` tools and then build a model with ```Rekognition``` to automatically annotate the rest of data. These automatically generated annotations may be additionaly checked and modified manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0406c",
   "metadata": {},
   "source": [
    "All the experiments described in this tutorial were done with [RESISC45](https://paperswithcode.com/dataset/resisc45) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10339b7a",
   "metadata": {},
   "source": [
    "The tutorial starts with the assumption that we have partially annotated dataset of images.\n",
    "The data is stored on S3 bucket and splitted into two parts: \n",
    "* train (~17%) $-$ annotated data for training\n",
    "* unlabeled (~83%) $-$ data that will be annotated by the model\n",
    "\n",
    "This folders are connected with existing SuperAnnotate project and train dataset has already been annotated manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f2e67b",
   "metadata": {},
   "source": [
    "![](../docs/image_classification_rekognition/folders.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde49308",
   "metadata": {},
   "source": [
    "In the examples below we used ```SuperAnnotate SDK``` and ```Boto3 SDK```. Some parts of code used here are provided as examples in [SuperAnnotate](https://doc.superannotate.com/docs/getting-started) and [Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) documentations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb18b9c",
   "metadata": {},
   "source": [
    "In this tutorial we will go through the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab77044",
   "metadata": {},
   "source": [
    "$\\textbf{1.}$ [Environmental setup](#envin_setup)\n",
    "\n",
    "$\\textbf{2.}$ [Create Rekognition project](#create_rekognition_project)\n",
    "\n",
    "\n",
    "$\\textbf{3.}$ [Create empty dataset](#create_empty_dataset)\n",
    "\n",
    "\n",
    "$\\textbf{4.}$ [Download Labels from SuperAnnotate](#download_labels_from_SA)\n",
    "\n",
    "\n",
    "$\\textbf{5.}$ [Upload labels to Rekognition Project for train data](#upload_labels_to_rekognition)\n",
    "\n",
    "\n",
    "$\\textbf{6.}$ [Move 20% of training data to test dataset](#move_20_to_test)\n",
    "\n",
    "\n",
    "$\\textbf{7.}$ [Train the model](#train_the_model)\n",
    "\n",
    "\n",
    "$\\textbf{8.}$ [Start the model](#start_the_model)\n",
    "\n",
    "\n",
    "$\\textbf{9.}$ [Test the prediction](#predict)\n",
    "\n",
    "\n",
    "$\\textbf{10.}$ [Predict unlabeled images](#predict_unlabeled_images)\n",
    "\n",
    "\n",
    "$\\textbf{11.}$ [Make SA annotations](#make_sa_annotations)\n",
    "\n",
    "\n",
    "$\\textbf{12.}$ [Upload new annotations to SA](#upload_new_annotations_to_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba95af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install superannotate==4.4.7 #SA SDK installation\n",
    "! pip install boto3 # install boto3 client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f801e92",
   "metadata": {},
   "source": [
    "### 1.1 User Variables Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b5124c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SuperAnnotate SDK token\n",
    "SA_TOKEN = \"ADD YOUR TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17b7b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_PROJECT_NAME = \"ADD SUPERANNOTATE PROJECT NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc97c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name for Rekognition project we will create\n",
    "REKOGNITION_PROJECT_NAME = \"ADD REKOGNITION PROJECT NAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579acfe7",
   "metadata": {},
   "source": [
    "### 1.2 Constants Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6056bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c4c0e9",
   "metadata": {},
   "source": [
    "SuperAnnotate Python SDK functions work within the team scope of the platform, so a team-level authorization is required.\n",
    "\n",
    "To authorize the package in a given team scope, get the authorization token from the team settings page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b9502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_client = SAClient(token=SA_TOKEN) ## SuperAnnotate client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b98de3",
   "metadata": {},
   "source": [
    "Data that is shown on SuperAnnotate page is actually stored on AWS S3 Bucket.\n",
    "Here we provide name of this bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47046ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"ADD YOUR BUCKET NAME\" # bucket where the data is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6321223",
   "metadata": {},
   "source": [
    "We should also create clients to be able to work with S3 and Rekognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe426fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3') ## S3 client\n",
    "\n",
    "rek_client = boto3.client('rekognition') ## Rekognition client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4bad2",
   "metadata": {},
   "source": [
    "Images shown on SuperAnnotate page are stored in S3 bucket.\n",
    "We can add them to Rekognition project and train the model using them.\n",
    "\n",
    "Before that we should get links to all of them.\n",
    "Since S3 SDK could list only 1000 objects per step, we could do it iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899fa384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this dict will contain S3 paths to train and unlabeled images\n",
    "data_links_dict = {'train': [],\n",
    "                   'unlabeled': []}\n",
    "\n",
    "#path to the folder containing images in S3 bucket\n",
    "BUCKET_FOLDER_PATH = '/path/to/data/'\n",
    "\n",
    "image_format = '.jpg'\n",
    "start_key = ''\n",
    "max_keys = 1000\n",
    "\n",
    "for subset_name in ['train', 'unlabeled']:\n",
    "    while True:\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name,\n",
    "                                             Prefix=f'{BUCKET_FOLDER_PATH}/{subset_name}/',\n",
    "                                             StartAfter=start_key,\n",
    "                                             MaxKeys=max_keys)\n",
    "        objects = response['Contents']\n",
    "        for obj in objects:\n",
    "            path = obj['Key']\n",
    "            if path.endswith(image_format):\n",
    "                data_links_dict[subset_name].append(obj['Key'])\n",
    "        start_key = objects[-1]['Key']\n",
    "        if len(objects) < max_keys:\n",
    "            start_key = ''\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34287e34",
   "metadata": {},
   "source": [
    "## 2. Create Rekognition project\n",
    "<a id='create_rekognition_project'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654de70",
   "metadata": {},
   "source": [
    "Now we can move to Rekognition and create an empty project there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rek_client.create_project(ProjectName=REKOGNITION_PROJECT_NAME)\n",
    "project_arn = response['ProjectArn'] ## store project's ARN to use it later\n",
    "print(project_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d28613",
   "metadata": {},
   "source": [
    "## 3. Create Empty Dataset\n",
    "<a id='create_empty_dataset'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd66f489",
   "metadata": {},
   "source": [
    "In order to train the model on our data we should upload the data to Rekognition platform.\n",
    "We create an empty dataset for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1445a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import argparse\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "def create_empty_dataset(rek_client, project_arn, dataset_type):\n",
    "    \"\"\"\n",
    "    Creates an empty Amazon Rekognition Custom Labels dataset.\n",
    "    :param rek_client: The Amazon Rekognition Custom Labels Boto3 client.\n",
    "    :param project_arn: The ARN of the project in which you want to create a dataset.\n",
    "    :param dataset_type: The type of the dataset that you want to create (train or test).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #Create the dataset\n",
    "        print(f\"Creating empty {dataset_type} dataset for project {project_arn}\")\n",
    "\n",
    "        dataset_type = dataset_type.upper()\n",
    "\n",
    "        response = rek_client.create_dataset(ProjectArn=project_arn,\n",
    "                                             DatasetType=dataset_type)\n",
    "\n",
    "        dataset_arn = response['DatasetArn']\n",
    "\n",
    "        print(f\"dataset ARN: {dataset_arn}\")\n",
    "\n",
    "        finished = False\n",
    "        while not finished:\n",
    "\n",
    "            dataset = rek_client.describe_dataset(DatasetArn=dataset_arn)\n",
    "\n",
    "            status = dataset['DatasetDescription']['Status']\n",
    "            \n",
    "            if status == \"CREATE_IN_PROGRESS\":\n",
    "                \n",
    "                print((f\"Creating dataset: {dataset_arn} \"))\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "\n",
    "            if status == \"CREATE_COMPLETE\":\n",
    "                print(f\"Dataset created: {dataset_arn}\")\n",
    "                finished = True\n",
    "                continue\n",
    "\n",
    "            if status == \"CREATE_FAILED\":\n",
    "                raise Exception (f\"Dataset creation failed: {status} : {dataset_arn}\")\n",
    "                \n",
    "            \n",
    "        return dataset_arn\n",
    "       \n",
    "    except ClientError as err:  \n",
    "        print(f\"Could not create dataset: {err.response['Error']['Message']}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19acc534",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'train'\n",
    "\n",
    "try:\n",
    "    print(f\"Creating empty {dataset_type} dataset for project {project_arn}\")\n",
    "\n",
    "    #Create the empty dataset\n",
    "    train_dataset_arn=create_empty_dataset(rek_client, \n",
    "                                           project_arn,\n",
    "                                           dataset_type.lower())\n",
    "\n",
    "    print(f\"Finished creating empty dataset: {train_dataset_arn}\")\n",
    "\n",
    "except Exception as err:\n",
    "    print(f\"Problem creating empty dataset: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50110da9",
   "metadata": {},
   "source": [
    "## 4. Download Labels from SA\n",
    "<a id='download_labels_from_SA'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [os.path.basename(x) for x in data_links_dict['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ff6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = sa_client.get_annotations(project=f\"{SA_PROJECT_NAME}/train\", \n",
    "                                        items=filenames)\n",
    "\n",
    "labels = [a['instances'][0]['className'] for a in annotations]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940ea03",
   "metadata": {},
   "source": [
    "## 5. Upload labels to Rekognition Project for train data\n",
    "<a id='upload_labels_to_rekognition'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa41c77",
   "metadata": {},
   "source": [
    "Now we can add our images from S3 bucket to Rekognition Dataset that was created in previous section.\n",
    "\n",
    "We will do it via manifest file that will containt urls for all our images. \n",
    "\n",
    "For more information read about [adding images with manifest files](https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/md-add-images.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_manifest_file(bucket_name,\n",
    "                         folder_path,\n",
    "                         filenames,\n",
    "                         labels,\n",
    "                         manifest_file_name):\n",
    "    s3_folder = f\"s3://{bucket_name}/{folder_path}\"\n",
    "    image_count = 0\n",
    "    with open(manifest_file_name, \"w\", encoding=\"UTF-8\") as output_file:\n",
    "        for filename, class_name in zip(filenames, labels):\n",
    "            if len(filename) ==  0:\n",
    "                continue\n",
    "                \n",
    "            json_line = {\"source-ref\": f\"{s3_folder}/{filename}\",\n",
    "                         \"imagelabel\": 0,\n",
    "                         \"imagelabel-metadata\": {\"class-name\": class_name,\n",
    "                                                 \"confidence\": 1.0,\n",
    "                                                 \"human-annotated\": \"yes\",\n",
    "                                                 \"type\": \"groundtruth/image-classification\",\n",
    "                                                 \"creation-date\": datetime.now().strftime(\"%Y-%m-%d:%H:%M:%S\"),\n",
    "                                                 \"job-name\": \"Test job\"}}\n",
    "            output_file.write(json.dumps(json_line))\n",
    "            output_file.write('\\n')\n",
    "            image_count += 1\n",
    "    return image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "updates_file_name = './train.manifest'\n",
    "\n",
    "create_manifest_file(bucket_name=data_bucket_name,\n",
    "                     folder_path=BUCKET_FOLDER_PATH,\n",
    "                     filenames=filenames,\n",
    "                     labels=lables,\n",
    "                     manifest_file_name=updates_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataset_entries(rek_client, dataset_arn, updates_file):\n",
    "    \"\"\"\n",
    "    Adds dataset entries to an Amazon Rekognition Custom Labels dataset.    \n",
    "    :param rek_client: The Amazon Rekognition Custom Labels Boto3 client.\n",
    "    :param dataset_arn: The ARN of the dataset that yuo want to update.\n",
    "    :param updates_file: The manifest file of JSON Lines that contains the updates. \n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        status = \"\"\n",
    "        status_message = \"\"\n",
    "\n",
    "        #Update dataset entries\n",
    "        print(f\"Updating dataset {dataset_arn}\")\n",
    "\n",
    "\n",
    "        with open(updates_file) as f:\n",
    "            manifest_file = f.read()\n",
    "\n",
    "        \n",
    "        changes=json.loads('{ \"GroundTruth\" : ' +\n",
    "            json.dumps(manifest_file) + \n",
    "            '}')\n",
    "        print(f\"{len(changes['GroundTruth'])} to add\")\n",
    "        rek_client.update_dataset_entries(Changes=changes,\n",
    "                                          DatasetArn=dataset_arn)\n",
    "        print(f\"Updated dataset {dataset_arn}\")\n",
    "        finished = False\n",
    "        while finished == False:\n",
    "\n",
    "            dataset = rek_client.describe_dataset(DatasetArn=dataset_arn)\n",
    "\n",
    "            status = dataset['DatasetDescription']['Status']\n",
    "            status_message = dataset['DatasetDescription']['StatusMessage']\n",
    "            \n",
    "            if status == \"UPDATE_IN_PROGRESS\":\n",
    "                print((f\"Updating dataset: {dataset_arn} \"))\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "\n",
    "            if status == \"UPDATE_COMPLETE\":\n",
    "                print(f\"Dataset updated: {status} : {status_message} : {dataset_arn}\")\n",
    "                finished=True\n",
    "                continue\n",
    "\n",
    "            if status == \"UPDATE_FAILED\":\n",
    "                print(f\"Dataset update failed: {status} : {status_message} : {dataset_arn}\")\n",
    "                raise Exception (f\"Dataset update failed: {status} : {status_message} : {dataset_arn}\")\n",
    "                \n",
    "\n",
    "            print(f\"Failed. Unexpected state for dataset update: {status} : {status_message} : {dataset_arn}\")\n",
    "            raise Exception(f\"Failed. Unexpected state for dataset update: {status} : {status_message} :{dataset_arn}\")\n",
    "            \n",
    "        print(f\"Added entries to dataset\")\n",
    "        \n",
    "        return status, status_message\n",
    "   \n",
    "    \n",
    "    except ClientError as err:  \n",
    "        print(f\"Couldn't update dataset: {err.response['Error']['Message']}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(f\"Updating dataset {train_dataset_arn} with entries from {updates_file_name}.\")\n",
    "\n",
    "    status, status_message=update_dataset_entries(rek_client, \n",
    "                                                  train_dataset_arn,\n",
    "                                                  updates_file_name)\n",
    "\n",
    "    print(f\"Finished updates dataset: {status} : {status_message}\")\n",
    "except Exception as err:\n",
    "    print(f\"Problem updating dataset: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c69e81c",
   "metadata": {},
   "source": [
    "## 6. Move 20% of training data to test dataset\n",
    "<a id='move_20_to_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c876cb87",
   "metadata": {},
   "source": [
    "To train the model we should specify training and test datasets.\n",
    "We will move 20% of our training data from train to test dataset. \n",
    "\n",
    "\n",
    "After model training is complete the model's performance will be evaluated using test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b809d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'test'\n",
    "\n",
    "try:\n",
    "    print(f\"Creating empty {dataset_type} dataset for project {project_arn}\")\n",
    "\n",
    "    #Create the empty dataset\n",
    "    test_dataset_arn=create_empty_dataset(rek_client, \n",
    "                                          project_arn,\n",
    "                                          dataset_type.lower())\n",
    "\n",
    "    print(f\"Finished creating empty dataset: {test_dataset_arn}\")\n",
    "\n",
    "except Exception as err:\n",
    "    print(f\"Problem creating empty dataset: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb8d314",
   "metadata": {},
   "source": [
    "We can distribute data between test and train automatically by using $ \\textit{distribute_dataset_entries}$ method from boto3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55638684",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = json.loads(\n",
    "            '[{\"Arn\" : \"' + str(train_dataset_arn) + '\"},{\"Arn\" : \"' + str(test_dataset_arn) + '\"}]')\n",
    "\n",
    "rek_client.distribute_dataset_entries(Datasets=datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f57233",
   "metadata": {},
   "source": [
    "## 7. Train the model\n",
    "<a id='train_the_model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05f4c3",
   "metadata": {},
   "source": [
    "Now we can train our model. We will use $create\\_project\\_version$ from boto3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c174ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(rek_client, \n",
    "                project_arn, \n",
    "                version_name, \n",
    "                output_bucket, \n",
    "                output_folder, \n",
    "                tag_key = None, \n",
    "                tag_key_value = None):\n",
    "    \"\"\"\n",
    "    Trains an Amazon Rekognition Custom Labels model.\n",
    "    :param rek_client: The Amazon Rekognition Custom Labels Boto3 client.\n",
    "    :param project_arn: The ARN of the project in which you want to train a model.\n",
    "    :param version_name: A version for the model.\n",
    "    :param output_bucket: The S3 bucket that hosts training output.\n",
    "    :param output_folder: The path for the training output within output_bucket\n",
    "    :param tag_key: The name of a tag to attach to the model. Pass None to exclude\n",
    "    :param tag_key_value: The value of the tag. Pass None to exclude\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        #Train the model\n",
    "\n",
    "        status=\"\" \n",
    "        print(f\"training model version {version_name} for project {project_arn}\")\n",
    "\n",
    "\n",
    "        output_config = json.loads(\n",
    "            '{\"S3Bucket\": \"'\n",
    "            + output_bucket\n",
    "            + '\", \"S3KeyPrefix\": \"'\n",
    "            + output_folder\n",
    "            + '\" }  '\n",
    "        )\n",
    "\n",
    "        tags = {}\n",
    "\n",
    "        if tag_key != None and tag_key_value != None:\n",
    "            tags = json.loads('{\"' + tag_key + '\":\"' + tag_key_value + '\"}')\n",
    "\n",
    "        response = rek_client.create_project_version(ProjectArn=project_arn, \n",
    "                                                     VersionName=version_name,\n",
    "                                                     OutputConfig=output_config,\n",
    "                                                     Tags=tags)\n",
    "\n",
    "        print(f\"Started training: {response['ProjectVersionArn']}\")\n",
    "\n",
    "        # Wait for the project version training to complete\n",
    "        project_version_training_completed_waiter = rek_client.get_waiter('project_version_training_completed')\n",
    "        project_version_training_completed_waiter.wait(ProjectArn=project_arn,\n",
    "                                                       VersionNames=[version_name])\n",
    "    \n",
    "\n",
    "        #Get the completion status\n",
    "        describe_response = rek_client.describe_project_versions(ProjectArn=project_arn,\n",
    "                                                                 VersionNames=[version_name])\n",
    "        for model in describe_response['ProjectVersionDescriptions']:\n",
    "            print(\"Status: \" + model['Status'])\n",
    "            print(\"Message: \" + model['StatusMessage']) \n",
    "            status = model['Status']\n",
    "\n",
    "\n",
    "        print(f\"finished training\")\n",
    "\n",
    "        return response['ProjectVersionArn'], status\n",
    "    \n",
    "    except ClientError as err:  \n",
    "        print(f\"Couldn't create model: {err.response['Error']['Message']}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b797128",
   "metadata": {},
   "source": [
    "We should specify name for model's version and place (bucket and folder) for Rekognition to store its output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_name = \"NAME OF MODEL'S VERSION\"\n",
    "output_bucket = \"OUTPUT BUCKET NAME\"\n",
    "output_folder = \"/PATH/TO/OUTPUT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.put_object(Bucket=bucket_name, Key=(output_folder+'/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10942b24",
   "metadata": {},
   "source": [
    "Here we will start model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4538199",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    print(f\"Training model version {version_name} for project {project_arn}\")\n",
    "\n",
    "    model_arn, status = train_model(rek_client, \n",
    "                                    project_arn,\n",
    "                                    version_name,\n",
    "                                    output_bucket,\n",
    "                                    output_folder)\n",
    "\n",
    "    print(f\"Finished training model: {model_arn}\")\n",
    "    print(f\"Status: {status}\")\n",
    "\n",
    "except Exception as err:\n",
    "    print(f\"Problem training model: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae6b8c",
   "metadata": {},
   "source": [
    "While the code cell above is running you could see the model with status \"TRAINING_IN_PROGRESS\" on Rekognition webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4e4ff",
   "metadata": {},
   "source": [
    "![](../docs/image_classification_rekognition/training_in_progress.png \"Training in progress\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e41486",
   "metadata": {},
   "source": [
    "## 8. Start the model\n",
    "\n",
    "<a id='start_the_model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6286a",
   "metadata": {},
   "source": [
    "Once training process is completed we can see that model status on Rekognition page is now \"Training completed\" and model is ready to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf95a335",
   "metadata": {},
   "source": [
    "![](../docs/image_classification_rekognition/model_ready_to_run.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a34d75",
   "metadata": {},
   "source": [
    "Since we have our model trained we can now use it to get the predictions for unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e1c9c",
   "metadata": {},
   "source": [
    "Before that we should start the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fdaa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_model(client, project_arn, model_arn, version_name, min_inference_units):\n",
    "\n",
    "    try:\n",
    "        # Start the modelstart_the_model\n",
    "        print('Starting model: ' + model_arn)\n",
    "        response=client.start_project_version(ProjectVersionArn=model_arn, MinInferenceUnits=min_inference_units)\n",
    "        # Wait for the model to be in the running state\n",
    "        project_version_running_waiter = client.get_waiter('project_version_running')\n",
    "        project_version_running_waiter.wait(ProjectArn=project_arn, VersionNames=[version_name])\n",
    "\n",
    "        #Get the running status\n",
    "        describe_response=client.describe_project_versions(ProjectArn=project_arn,\n",
    "            VersionNames=[version_name])\n",
    "        for model in describe_response['ProjectVersionDescriptions']:\n",
    "            print(\"Status: \" + model['Status'])\n",
    "            print(\"Message: \" + model['StatusMessage']) \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    print('Done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70110780",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_model(rek_client,\n",
    "            project_arn, \n",
    "            model_arn, \n",
    "            version_name, \n",
    "            min_inference_units=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f699d",
   "metadata": {},
   "source": [
    "After the cell above is finished we could see that model status on Rekognition page is now \"Running\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe04696",
   "metadata": {},
   "source": [
    "![](../docs/image_classification_rekognition/model_is_running.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3525a10",
   "metadata": {},
   "source": [
    "## 9. Prediction test\n",
    "<a id='predict'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f21b17",
   "metadata": {},
   "source": [
    "Now the model is ready to run and we can get prediction for any unlabeled image we have.\n",
    "We have to provide a path to S3 bucket and folder where the image is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1468d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_custom_labels(client, model, bucket, photo, min_confidence):\n",
    "    response = client.detect_custom_labels(Image={'S3Object': {'Bucket': bucket, \n",
    "                                                                 'Name': photo}},\n",
    "                                           MinConfidence=min_confidence,\n",
    "                                           ProjectVersionArn=model)\n",
    "    return response['CustomLabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'FILE TO TEST'\n",
    "photo = f'{BUCKET_FOLDER_PATH}/unlabeled/{filename}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68398604",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_confidence = 10 ## minimum confindence model should have for the label to detect it\n",
    "\n",
    "labels = show_custom_labels(rek_client, model_arn, bucket_name, photo, min_confidence)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6d2788",
   "metadata": {},
   "source": [
    "## 10. Predict unlabeled images\n",
    "<a id='predict_unlabeled_images'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5134cf3e",
   "metadata": {},
   "source": [
    "We can now get the predictions for all our unlabeled images.\n",
    "\n",
    "We could use the function $\\textit{show_custom_labels}$ and dictionary with S3 paths to all unlabeld images $data\\_ links\\_dict$ that we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9314fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels  = {}\n",
    "\n",
    "for photo_path in tqdm(data_links_dict['unlabeled']):\n",
    "    labels = show_custom_labels(rek_client, model_arn, bucket, photo_path, min_confidence)\n",
    "    predicted_labels[photo_path] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc94a3",
   "metadata": {},
   "source": [
    "## 11. Make SA annotations\n",
    "<a id='make_sa_annotations'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f80c2f",
   "metadata": {},
   "source": [
    "Based on predictions made by the model we should now create annotations in SuperAnnotate format to be able to upload them to SuperAnnotate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f92fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_FOLDER = 'PATH/TO/LOCAL/DIR/' # local folder to store .json files with annotations\n",
    "for image_path, label in predicted_labels.items():\n",
    "    filename = os.path.basename(image_path)\n",
    "    js_annotation = {\"metadata\": {\"name\": filename},\n",
    "                     \"instances\": [{\"type\": \"tag\",\n",
    "                                    \"className\": label[0]['Name']}]}\n",
    "    with open(f'{ANNOTATIONS FOLDER}/{filename}.json','w') as f:\n",
    "        json.dump(js_annotation, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eff4e3e",
   "metadata": {},
   "source": [
    "## 12. Upload new annotations to SA \n",
    "<a id='upload_new_annotations_to_sa'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a3528e",
   "metadata": {},
   "source": [
    "Now we could upload annotations generated on the previous step back to SuperAnnnotate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8bc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_js(filename):\n",
    "    with open(filename) as f:\n",
    "        js = json.load(f)\n",
    "    return js "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "full_dirname = ANNOTATIONS_FOLDER\n",
    "files = os.listdir(full_dirname)\n",
    "files_per_step = 500\n",
    "steps = len(files) // files_per_step + 1\n",
    "\n",
    "for step in range(steps):\n",
    "    start = step * files_per_step\n",
    "    end = min((step + 1)* files_per_step, len(files))\n",
    "\n",
    "    batch = [read_js(os.path.join(full_dirname, f)) for f in files[start: end]]\n",
    "\n",
    "    outputs.append(sa_client.upload_annotations(project=f'{SA_PROJECT_NAME}/unlabeled/', annotations=batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea54fe3",
   "metadata": {},
   "source": [
    "Now we can look at unlabeled folder at the SuperAnnotate page and see the predictions made by our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d5bde",
   "metadata": {},
   "source": [
    "All files in unlabeled folder changed their status."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8dbe02",
   "metadata": {},
   "source": [
    "![](../docs/image_classification_rekognition/unlabeled_status_changed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae0900b",
   "metadata": {},
   "source": [
    "We can open any of these files and check whether it is annitated correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86895803",
   "metadata": {},
   "source": [
    "![](../docs/image_classification_rekognition/airplane_example.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
